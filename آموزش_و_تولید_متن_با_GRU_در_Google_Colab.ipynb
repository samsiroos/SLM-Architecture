{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samsiroos/SLM-Architecture/blob/main/%D8%A2%D9%85%D9%88%D8%B2%D8%B4_%D9%88_%D8%AA%D9%88%D9%84%DB%8C%D8%AF_%D9%85%D8%AA%D9%86_%D8%A8%D8%A7_GRU_%D8%AF%D8%B1_Google_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# وارد کردن کتابخانه‌های لازم\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "print(\"کتابخانه‌ها با موفقیت وارد شدند.\")\n",
        "\n",
        "# --- ۱. آماده‌سازی داده‌ها ---\n",
        "# متن نمونه طولانی‌تر برای آموزش مدل.\n",
        "# این متن شبیه‌سازی یک فایل متنی با حدود 300 خط است.\n",
        "# در سناریوهای واقعی، این متن از یک فایل بزرگتر (مثلاً یک کتاب) بارگذاری می‌شود.\n",
        "text = \"\"\"\n",
        "جهان هستی پر از شگفتی‌هاست. هر ستاره در آسمان شب، داستانی ناگفته دارد. کهکشان‌ها با میلیاردها ستاره، منظومه‌های شمسی بی‌شمار را در خود جای داده‌اند. زمین، سیاره آبی ما، تنها گوشه‌ای از این عظمت بی‌کران است. حیات در آن به شکل‌های گوناگون جریان دارد. از کوچکترین میکروارگانیسم‌ها تا بزرگترین نهنگ‌ها. همه و همه بخشی از این چرخه شگفت‌انگیز هستند.\n",
        "\n",
        "علم به ما کمک می‌کند تا این رازها را کشف کنیم. فیزیک، شیمی، زیست‌شناسی، و نجوم. هر کدام دریچه‌ای نو به سوی درک عمیق‌تر جهان می‌گشایند. اکتشافات علمی، مرزهای دانش بشری را جابجا می‌کنند. از نظریه نسبیت انیشتین تا کشف ساختار DNA. این پیشرفت‌ها زندگی ما را متحول کرده‌اند.\n",
        "\n",
        "فناوری نیز نقش مهمی در این مسیر ایفا می‌کند. از تلسکوپ‌های فضایی قدرتمند تا میکروسکوپ‌های الکترونی پیشرفته. ابزارهایی که به ما امکان مشاهده نادیده‌ها را می‌دهند. هوش مصنوعی و یادگیری ماشینی، حوزه‌های نوظهوری هستند. که پتانسیل عظیمی برای حل مشکلات پیچیده دارند. مدل‌های زبانی بزرگ، نمونه بارز این پیشرفت‌ها هستند.\n",
        "\n",
        "اما یادگیری فقط به علم و فناوری محدود نمی‌شود. ادبیات، هنر، فلسفه و تاریخ. این‌ها نیز ابعادی از دانش بشری را شکل می‌دهند. که به روح انسان عمق می‌بخشند. مطالعه تاریخ به ما کمک می‌کند تا از گذشته درس بگیریم. و آینده‌ای بهتر بسازیم. ادبیات، دریچه‌ای به سوی احساسات و تجربیات انسانی است. هنر، بیانگر زیبایی و خلاقیت است.\n",
        "\n",
        "محیط زیست ما در خطر است. تغییرات اقلیمی، آلودگی هوا و آب. از بین رفتن تنوع زیستی. این‌ها چالش‌های بزرگی هستند که با آن‌ها روبرو هستیم. حفاظت از سیاره زمین، مسئولیت همه ماست. با اقدامات کوچک می‌توانیم تاثیرات بزرگی ایجاد کنیم. کاهش مصرف انرژی، بازیافت، و حمایت از انرژی‌های پاک.\n",
        "\n",
        "آموزش و پرورش، ستون فقرات توسعه هر جامعه است. دسترسی به آموزش با کیفیت برای همه، یک حق اساسی است. مدارس و دانشگاه‌ها باید محیطی برای رشد و شکوفایی استعدادها باشند. یادگیری مادام‌العمر، کلید موفقیت در دنیای امروز است.\n",
        "\n",
        "سلامتی و تندرستی نیز از اهمیت بالایی برخوردار است. تغذیه سالم، ورزش منظم، و خواب کافی. این‌ها عوامل کلیدی برای یک زندگی سالم هستند. پیشرفت‌های پزشکی، امید به زندگی را افزایش داده‌اند. اما پیشگیری همیشه بهتر از درمان است.\n",
        "\n",
        "ارتباطات انسانی، پایه و اساس جوامع است. احترام متقابل، همدلی، و درک تفاوت‌ها. این‌ها به ساختن جامعه‌ای صلح‌آمیز کمک می‌کنند. رسانه‌های اجتماعی، ابزارهای قدرتمندی برای ارتباط هستند. اما باید با هوشیاری از آن‌ها استفاده کرد.\n",
        "\n",
        "اقتصاد جهانی در حال تحول است. دیجیتالی شدن، جهانی شدن، و نوآوری. این‌ها نیروهای محرک اقتصاد امروز هستند. کارآفرینی و خلاقیت، موتور رشد اقتصادی هستند. ایجاد فرصت‌های شغلی جدید، از اولویت‌هاست.\n",
        "\n",
        "فرهنگ هر جامعه، هویت آن را شکل می‌دهد. آداب و رسوم، زبان، و ارزش‌ها. این‌ها میراثی گرانبها هستند که باید حفظ شوند. تبادل فرهنگی، به غنی‌سازی جوامع کمک می‌کند.\n",
        "\n",
        "در نهایت، زندگی مجموعه‌ای از تجربیات است. یادگیری از اشتباهات، قدردانی از لحظات خوب. و تلاش برای بهتر شدن. هر روز فرصتی جدید برای رشد و پیشرفت است. با امید به آینده‌ای روشن‌تر.\n",
        "\n",
        "جهان هستی پر از شگفتی‌هاست. هر ستاره در آسمان شب، داستانی ناگفته دارد. کهکشان‌ها با میلیاردها ستاره، منظومه‌های شمسی بی‌شمار را در خود جای داده‌اند. زمین، سیاره آبی ما، تنها گوشه‌ای از این عظمت بی‌کران است. حیات در آن به شکل‌های گوناگون جریان دارد. از کوچکترین میکروارگانیسم‌ها تا بزرگترین نهنگ‌ها. همه و همه بخشی از این چرخه شگفت‌انگیز هستند.\n",
        "\n",
        "علم به ما کمک می‌کند تا این رازها را کشف کنیم. فیزیک، شیمی، زیست‌شناسی، و نجوم. هر کدام دریچه‌ای نو به سوی درک عمیق‌تر جهان می‌گشایند. اکتشافات علمی، مرزهای دانش بشری را جابجا می‌کنند. از نظریه نسبیت انیشتین تا کشف ساختار DNA. این پیشرفت‌ها زندگی ما را متحول کرده‌اند.\n",
        "\n",
        "فناوری نیز نقش مهمی در این مسیر ایفا می‌کند. از تلسکوپ‌های فضایی قدرتمند تا میکروسکوپ‌های الکترونی پیشرفته. ابزارهایی که به ما امکان مشاهده نادیده‌ها را می‌دهند. هوش مصنوعی و یادگیری ماشینی، حوزه‌های نوظهوری هستند. که پتانسیل عظیمی برای حل مشکلات پیچیده دارند. مدل‌های زبانی بزرگ، نمونه بارز این پیشرفت‌ها هستند.\n",
        "\n",
        "اما یادگیری فقط به علم و فناوری محدود نمی‌شود. ادبیات، هنر، فلسفه و تاریخ. این‌ها نیز ابعادی از دانش بشری را شکل می‌دهند. که به روح انسان عمق می‌بخشند. مطالعه تاریخ به ما کمک می‌کند تا از گذشته درس بگیریم. و آینده‌ای بهتر بسازیم. ادبیات، دریچه‌ای به سوی احساسات و تجربیات انسانی است. هنر، بیانگر زیبایی و خلاقیت است.\n",
        "\n",
        "محیط زیست ما در خطر است. تغییرات اقلیمی، آلودگی هوا و آب. از بین رفتن تنوع زیستی. این‌ها چالش‌های بزرگی هستند که با آن‌ها روبرو هستیم. حفاظت از سیاره زمین، مسئولیت همه ماست. با اقدامات کوچک می‌توانیم تاثیرات بزرگی ایجاد کنیم. کاهش مصرف انرژی، بازیافت، و حمایت از انرژی‌های پاک.\n",
        "\n",
        "آموزش و پرورش، ستون فقرات توسعه هر جامعه است. دسترسی به آموزش با کیفیت برای همه، یک حق اساسی است. مدارس و دانشگاه‌ها باید محیطی برای رشد و شکوفایی استعدادها باشند. یادگیری مادام‌العمر، کلید موفقیت در دنیای امروز است.\n",
        "\n",
        "سلامتی و تندرستی نیز از اهمیت بالایی برخوردار است. تغذیه سالم، ورزش منظم، و خواب کافی. این‌ها عوامل کلیدی برای یک زندگی سالم هستند. پیشرفت‌های پزشکی، امید به زندگی را افزایش داده‌اند. اما پیشگیری همیشه بهتر از درمان است.\n",
        "\n",
        "ارتباطات انسانی، پایه و اساس جوامع است. احترام متقابل، همدلی، و درک تفاوت‌ها. این‌ها به ساختن جامعه‌ای صلح‌آمیز کمک می‌کنند. رسانه‌های اجتماعی، ابزارهای قدرتمندی برای ارتباط هستند. اما باید با هوشیاری از آن‌ها استفاده کرد.\n",
        "\n",
        "اقتصاد جهانی در حال تحول است. دیجیتالی شدن، جهانی شدن، و نوآوری. این‌ها نیروهای محرک اقتصاد امروز هستند. کارآفرینی و خلاقیت، موتور رشد اقتصادی هستند. ایجاد فرصت‌های شغلی جدید، از اولویت‌هاست.\n",
        "\n",
        "فرهنگ هر جامعه، هویت آن را شکل می‌دهد. آداب و رسوم، زبان، و ارزش‌ها. این‌ها میراثی گرانبها هستند که باید حفظ شوند. تبادل فرهنگی، به غنی‌سازی جوامع کمک می‌کند.\n",
        "\n",
        "در نهایت، زندگی مجموعه‌ای از تجربیات است. یادگیری از اشتباهات، قدردانی از لحظات خوب. و تلاش برای بهتر شدن. هر روز فرصتی جدید برای رشد و پیشرفت است. با امید به آینده‌ای روشن‌تر.\n",
        "\n",
        "جهان هستی پر از شگفتی‌هاست. هر ستاره در آسمان شب، داستانی ناگفته دارد. کهکشان‌ها با میلیاردها ستاره، منظومه‌های شمسی بی‌شمار را در خود جای داده‌اند. زمین، سیاره آبی ما، تنها گوشه‌ای از این عظمت بی‌کران است. حیات در آن به شکل‌های گوناگون جریان دارد. از کوچکترین میکروارگانیسم‌ها تا بزرگترین نهنگ‌ها. همه و همه بخشی از این چرخه شگفت‌انگیز هستند.\n",
        "\n",
        "علم به ما کمک می‌کند تا این رازها را کشف کنیم. فیزیک، شیمی، زیست‌شناسی، و نجوم. هر کدام دریچه‌ای نو به سوی درک عمیق‌تر جهان می‌گشایند. اکتشافات علمی، مرزهای دانش بشری را جابجا می‌کنند. از نظریه نسبیت انیشتین تا کشف ساختار DNA. این پیشرفت‌ها زندگی ما را متحول کرده‌اند.\n",
        "\n",
        "فناوری نیز نقش مهمی در این مسیر ایفا می‌کند. از تلسکوپ‌های فضایی قدرتمند تا میکروسکوپ‌های الکترونی پیشرفته. ابزارهایی که به ما امکان مشاهده نادیده‌ها را می‌دهند. هوش مصنوعی و یادگیری ماشینی، حوزه‌های نوظهوری هستند. که پتانسیل عظیمی برای حل مشکلات پیچیده دارند. مدل‌های زبانی بزرگ، نمونه بارز این پیشرفت‌ها هستند.\n",
        "\n",
        "اما یادگیری فقط به علم و فناوری محدود نمی‌شود. ادبیات، هنر، فلسفه و تاریخ. این‌ها نیز ابعادی از دانش بشری را شکل می‌دهند. که به روح انسان عمق می‌بخشند. مطالعه تاریخ به ما کمک می‌کند تا از گذشته درس بگیریم. و آینده‌ای بهتر بسازیم. ادبیات، دریچه‌ای به سوی احساسات و تجربیات انسانی است. هنر، بیانگر زیبایی و خلاقیت است.\n",
        "\n",
        "محیط زیست ما در خطر است. تغییرات اقلیمی، آلودگی هوا و آب. از بین رفتن تنوع زیستی. این‌ها چالش‌های بزرگی هستند که با آن‌ها روبرو هستیم. حفاظت از سیاره زمین، مسئولیت همه ماست. با اقدامات کوچک می‌توانیم تاثیرات بزرگی ایجاد کنیم. کاهش مصرف انرژی، بازیافت، و حمایت از انرژی‌های پاک.\n",
        "\n",
        "آموزش و پرورش، ستون فقرات توسعه هر جامعه است. دسترسی به آموزش با کیفیت برای همه، یک حق اساسی است. مدارس و دانشگاه‌ها باید محیطی برای رشد و شکوفایی استعدادها باشند. یادگیری مادام‌العمر، کلید موفقیت در دنیای امروز است.\n",
        "\n",
        "سلامتی و تندرستی نیز از اهمیت بالایی برخوردار است. تغذیه سالم، ورزش منظم، و خواب کافی. این‌ها عوامل کلیدی برای یک زندگی سالم هستند. پیشرفت‌های پزشکی، امید به زندگی را افزایش داده‌اند. اما پیشگیری همیشه بهتر از درمان است.\n",
        "\n",
        "ارتباطات انسانی، پایه و اساس جوامع است. احترام متقابل، همدلی، و درک تفاوت‌ها. این‌ها به ساختن جامعه‌ای صلح‌آمیز کمک می‌کنند. رسانه‌های اجتماعی، ابزارهای قدرتمندی برای ارتباط هستند. اما باید با هوشیاری از آن‌ها استفاده کرد.\n",
        "\n",
        "اقتصاد جهانی در حال تحول است. دیجیتالی شدن، جهانی شدن، و نوآوری. این‌ها نیروهای محرک اقتصاد امروز هستند. کارآفرینی و خلاقیت، موتور رشد اقتصادی هستند. ایجاد فرصت‌های شغلی جدید، از اولویت‌هاست.\n",
        "\n",
        "فرهنگ هر جامعه، هویت آن را شکل می‌دهد. آداب و رسوم، زبان، و ارزش‌ها. این‌ها میراثی گرانبها هستند که باید حفظ شوند. تبادل فرهنگی، به غنی‌سازی جوامع کمک می‌کند.\n",
        "\n",
        "در نهایت، زندگی مجموعه‌ای از تجربیات است. یادگیری از اشتباهات، قدردانی از لحظات خوب. و تلاش برای بهتر شدن. هر روز فرصتی جدید برای رشد و پیشرفت است. با امید به آینده‌ای روشن‌تر.\n",
        "\n",
        "جهان هستی پر از شگفتی‌هاست. هر ستاره در آسمان شب، داستانی ناگفته دارد. کهکشان‌ها با میلیاردها ستاره، منظومه‌های شمسی بی‌شمار را در خود جای داده‌اند. زمین، سیاره آبی ما، تنها گوشه‌ای از این عظمت بی‌کران است. حیات در آن به شکل‌های گوناگون جریان دارد. از کوچکترین میکروارگانیسم‌ها تا بزرگترین نهنگ‌ها. همه و همه بخشی از این چرخه شگفت‌انگیز هستند.\n",
        "\n",
        "علم به ما کمک می‌کند تا این رازها را کشف کنیم. فیزیک، شیمی، زیست‌شناسی، و نجوم. هر کدام دریچه‌ای نو به سوی درک عمیق‌تر جهان می‌گشایند. اکتشافات علمی، مرزهای دانش بشری را جابجا می‌کنند. از نظریه نسبیت انیشتین تا کشف ساختار DNA. این پیشرفت‌ها زندگی ما را متحول کرده‌اند.\n",
        "\n",
        "فناوری نیز نقش مهمی در این مسیر ایفا می‌کند. از تلسکوپ‌های فضایی قدرتمند تا میکروسکوپ‌های الکترونی پیشرفته. ابزارهایی که به ما امکان مشاهده نادیده‌ها را می‌دهند. هوش مصنوعی و یادگیری ماشینی، حوزه‌های نوظهوری هستند. که پتانسیل عظیمی برای حل مشکلات پیچیده دارند. مدل‌های زبانی بزرگ، نمونه بارز این پیشرفت‌ها هستند.\n",
        "\n",
        "اما یادگیری فقط به علم و فناوری محدود نمی‌شود. ادبیات، هنر، فلسفه و تاریخ. این‌ها نیز ابعادی از دانش بشری را شکل می‌دهند. که به روح انسان عمق می‌بخشند. مطالعه تاریخ به ما کمک می‌کند تا از گذشته درس بگیریم. و آینده‌ای بهتر بسازیم. ادبیات، دریچه‌ای به سوی احساسات و تجربیات انسانی است. هنر، بیانگر زیبایی و خلاقیت است.\n",
        "\n",
        "محیط زیست ما در خطر است. تغییرات اقلیمی، آلودگی هوا و آب. از بین رفتن تنوع زیستی. این‌ها چالش‌های بزرگی هستند که با آن‌ها روبرو هستیم. حفاظت از سیاره زمین، مسئولیت همه ماست. با اقدامات کوچک می‌توانیم تاثیرات بزرگی ایجاد کنیم. کاهش مصرف انرژی، بازیافت، و حمایت از انرژی‌های پاک.\n",
        "\n",
        "آموزش و پرورش، ستون فقرات توسعه هر جامعه است. دسترسی به آموزش با کیفیت برای همه، یک حق اساسی است. مدارس و دانشگاه‌ها باید محیطی برای رشد و شکوفایی استعدادها باشند. یادگیری مادام‌العمر، کلید موفقیت در دنیای امروز است.\n",
        "\n",
        "سلامتی و تندرستی نیز از اهمیت بالایی برخوردار است. تغذیه سالم، ورزش منظم، و خواب کافی. این‌ها عوامل کلیدی برای یک زندگی سالم هستند. پیشرفت‌های پزشکی، امید به زندگی را افزایش داده‌اند. اما پیشگیری همیشه بهتر از درمان است.\n",
        "\n",
        "ارتباطات انسانی، پایه و اساس جوامع است. احترام متقابل، همدلی، و درک تفاوت‌ها. این‌ها به ساختن جامعه‌ای صلح‌آمیز کمک می‌کنند. رسانه‌های اجتماعی، ابزارهای قدرتمندی برای ارتباط هستند. اما باید با هوشیاری از آن‌ها استفاده کرد.\n",
        "\n",
        "اقتصاد جهانی در حال تحول است. دیجیتالی شدن، جهانی شدن، و نوآوری. این‌ها نیروهای محرک اقتصاد امروز هستند. کارآفرینی و خلاقیت، موتور رشد اقتصادی هستند. ایجاد فرصت‌های شغلی جدید، از اولویت‌هاست.\n",
        "\n",
        "فرهنگ هر جامعه، هویت آن را شکل می‌دهد. آداب و رسوم، زبان، و ارزش‌ها. این‌ها میراثی گرانبها هستند که باید حفظ شوند. تبادل فرهنگی، به غنی‌سازی جوامع کمک می‌کند.\n",
        "\n",
        "در نهایت، زندگی مجموعه‌ای از تجربیات است. یادگیری از اشتباهات، قدردانی از لحظات خوب. و تلاش برای بهتر شدن. هر روز فرصتی جدید برای رشد و پیشرفت است. با امید به آینده‌ای روشن‌تر.\n",
        "\n",
        "جهان هستی پر از شگفتی‌هاست. هر ستاره در آسمان شب، داستانی ناگفته دارد. کهکشان‌ها با میلیاردها ستاره، منظومه‌های شمسی بی‌شمار را در خود جای داده‌اند. زمین، سیاره آبی ما، تنها گوشه‌ای از این عظمت بی‌کران است. حیات در آن به شکل‌های گوناگون جریان دارد. از کوچکترین میکروارگانیسم‌ها تا بزرگترین نهنگ‌ها. همه و همه بخشی از این چرخه شگفت‌انگیز هستند.\n",
        "\n",
        "علم به ما کمک می‌کند تا این رازها را کشف کنیم. فیزیک، شیمی، زیست‌شناسی، و نجوم. هر کدام دریچه‌ای نو به سوی درک عمیق‌تر جهان می‌گشایند. اکتشافات علمی، مرزهای دانش بشری را جابجا می‌کنند. از نظریه نسبیت انیشتین تا کشف ساختار DNA. این پیشرفت‌ها زندگی ما را متحول کرده‌اند.\n",
        "\n",
        "فناوری نیز نقش مهمی در این مسیر ایفا می‌کند. از تلسکوپ‌های فضایی قدرتمند تا میکروسکوپ‌های الکترونی پیشرفته. ابزارهایی که به ما امکان مشاهده نادیده‌ها را می‌دهند. هوش مصنوعی و یادگیری ماشینی، حوزه‌های نوظوری هستند. که پتانسیل عظیمی برای حل مشکلات پیچیده دارند. مدل‌های زبانی بزرگ، نمونه بارز این پیشرفت‌ها هستند.\n",
        "\n",
        "اما یادگیری فقط به علم و فناوری محدود نمی‌شود. ادبیات، هنر، فلسفه و تاریخ. این‌ها نیز ابعادی از دانش بشری را شکل می‌دهند. که به روح انسان عمق می‌بخشند. مطالعه تاریخ به ما کمک می‌کند تا از گذشته درس بگیریم. و آینده‌ای بهتر بسازیم. ادبیات، دریچه‌ای به سوی احساسات و تجربیات انسانی است. هنر، بیانگر زیبایی و خلاقیت است.\n",
        "\n",
        "محیط زیست ما در خطر است. تغییرات اقلیمی، آلودگی هوا و آب. از بین رفتن تنوع زیستی. این‌ها چالش‌های بزرگی هستند که با آن‌ها روبرو هستیم. حفاظت از سیاره زمین، مسئولیت همه ماست. با اقدامات کوچک می‌توانیم تاثیرات بزرگی ایجاد کنیم. کاهش مصرف انرژی، بازیافت، و حمایت از انرژی‌های پاک.\n",
        "\n",
        "آموزش و پرورش، ستون فقرات توسعه هر جامعه است. دسترسی به آموزش با کیفیت برای همه، یک حق اساسی است. مدارس و دانشگاه‌ها باید محیطی برای رشد و شکوفایی استعدادها باشند. یادگیری مادام‌العمر، کلید موفقیت در دنیای امروز است.\n",
        "\n",
        "سلامتی و تندرستی نیز از اهمیت بالایی برخوردار است. تغذیه سالم، ورزش منظم، و خواب کافی. این‌ها عوامل کلیدی برای یک زندگی سالم هستند. پیشرفت‌های پزشکی، امید به زندگی را افزایش داده‌اند. اما پیشگیری همیشه بهتر از درمان است.\n",
        "\n",
        "ارتباطات انسانی، پایه و اساس جوامع است. احترام متقابل، همدلی، و درک تفاوت‌ها. این‌ها به ساختن جامعه‌ای صلح‌آمیز کمک می‌کنند. رسانه‌های اجتماعی، ابزارهای قدرتمندی برای ارتباط هستند. اما باید با هوشیاری از آن‌ها استفاده کرد.\n",
        "\n",
        "اقتصاد جهانی در حال تحول است. دیجیتالی شدن، جهانی شدن، و نوآوری. این‌ها نیروهای محرک اقتصاد امروز هستند. کارآفرینی و خلاقیت، موتور رشد اقتصادی هستند. ایجاد فرصت‌های شغلی جدید، از اولویت‌هاست.\n",
        "\n",
        "فرهنگ هر جامعه، هویت آن را شکل می‌دهد. آداب و رسوم، زبان، و ارزش‌ها. این‌ها میراثی گرانبها هستند که باید حفظ شوند. تبادل فرهنگی، به غنی‌سازی جوامع کمک می‌کند.\n",
        "\n",
        "در نهایت، زندگی مجموعه‌ای از تجربیات است. یادگیری از اشتباهات، قدردانی از لحظات خوب. و تلاش برای بهتر شدن. هر روز فرصتی جدید برای رشد و پیشرفت است. با امید به آینده‌ای روشن‌تر.\n",
        "\"\"\"\n",
        "\n",
        "# تبدیل تمام متن به حروف کوچک برای یکسان‌سازی\n",
        "text = text.lower()\n",
        "print(f\"\\nمتن اصلی برای آموزش (بخش اول):\\n{text[:500]}...\\n\") # نمایش بخشی از متن\n",
        "\n",
        "# --- توکن‌سازی (Tokenization) ---\n",
        "# توکن‌سازی فرآیند تبدیل متن به دنباله‌ای از اعداد است.\n",
        "# هر کلمه منحصر به فرد یک عدد یکتا دریافت می‌کند.\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text]) # مدل توکن‌ساز را روی متن آموزش می‌دهیم تا کلمات را بشناسد\n",
        "word_index = tokenizer.word_index # دیکشنری کلمات به اعداد (ایندکس‌ها)\n",
        "print(f\"تعداد کلمات منحصر به فرد در واژه‌نامه: {len(word_index)}\\n\")\n",
        "\n",
        "# تعداد کل کلمات منحصر به فرد + 1 (برای کلماتی که در واژه‌نامه نیستند یا برای padding)\n",
        "total_words = len(word_index) + 1\n",
        "print(f\"تعداد کل کلمات منحصر به فرد در واژه‌نامه (با احتساب صفر): {total_words}\\n\")\n",
        "\n",
        "# --- ساخت دنباله‌های ورودی و خروجی برای آموزش ---\n",
        "# برای آموزش مدل، دنباله‌هایی از کلمات (n-grams) ایجاد می‌کنیم.\n",
        "input_sequences = []\n",
        "for line in text.split('\\n'):\n",
        "    if line.strip() == \"\": # خطوط خالی را نادیده می‌گیریم\n",
        "        continue\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0] # هر خط را به دنباله‌ای از اعداد تبدیل می‌کنیم\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1] # دنباله n-gram (از ابتدای خط تا کلمه فعلی)\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "print(f\"تعداد دنباله‌های ورودی برای آموزش: {len(input_sequences)}\\n\")\n",
        "print(f\"نمونه‌ای از دنباله‌های ورودی (اعداد):\\n{input_sequences[:5]}\\n\")\n",
        "\n",
        "# --- هم‌اندازه‌سازی دنباله‌ها (Padding) و تفکیک X و Y ---\n",
        "# شبکه‌های عصبی نیاز دارند که ورودی‌ها هم‌اندازه باشند.\n",
        "# بنابراین، دنباله‌های کوتاه‌تر را با صفر در ابتدا پر می‌کنیم (pre-padding).\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "print(f\"حداکثر طول دنباله در داده‌های آموزشی: {max_sequence_len}\\n\")\n",
        "\n",
        "padded_sequences = np.array(tf.keras.preprocessing.sequence.pad_sequences(input_sequences,\n",
        "                                                                          maxlen=max_sequence_len,\n",
        "                                                                          padding='pre'))\n",
        "\n",
        "# X (ورودی): تمام کلمات دنباله به جز آخرین کلمه\n",
        "X = padded_sequences[:, :-1]\n",
        "# labels (خروجی): فقط آخرین کلمه در هر دنباله (کلمه‌ای که می‌خواهیم پیش‌بینی کنیم)\n",
        "labels = padded_sequences[:, -1]\n",
        "\n",
        "# تبدیل خروجی (labels) به فرمت one-hot encoding\n",
        "# چون پیش‌بینی کلمه یک مسئله دسته‌بندی است، خروجی‌ها باید به صورت one-hot باشند.\n",
        "y = to_categorical(labels, num_classes=total_words)\n",
        "\n",
        "print(f\"ابعاد ورودی (X) برای مدل: {X.shape}\") # (تعداد نمونه‌ها, طول دنباله ورودی)\n",
        "print(f\"ابعاد خروجی (y) برای مدل (one-hot): {y.shape}\") # (تعداد نمونه‌ها, تعداد کل کلمات در واژه‌نامه)\n",
        "\n",
        "# --- ۲. ساخت مدل GRU ---\n",
        "# معماری مدل GRU را با پارامترهای جدید تعریف می‌کنیم.\n",
        "model = Sequential()\n",
        "# لایه Embedding: ابعاد بردار کلمه را به 256 افزایش می‌دهیم.\n",
        "# total_words: اندازه واژه‌نامه\n",
        "# 256: ابعاد بردار کلمه (embedding_dim)\n",
        "# input_length: طول دنباله ورودی به لایه GRU (max_sequence_len - 1)\n",
        "model.add(Embedding(total_words, 256, input_length=max_sequence_len-1))\n",
        "# لایه GRU اول: 512 واحد حافظه.\n",
        "# return_sequences=True: خروجی هر گام زمانی را برای لایه GRU بعدی ارسال می‌کند.\n",
        "model.add(GRU(512, return_sequences=True))\n",
        "# لایه GRU دوم: 512 واحد حافظه.\n",
        "# return_sequences=False: فقط خروجی آخرین گام زمانی را برای لایه Dense ارسال می‌کند.\n",
        "model.add(GRU(512, return_sequences=False))\n",
        "# لایه Dense: لایه خروجی با تابع فعال‌سازی softmax.\n",
        "# total_words: تعداد نورون‌ها برابر با تعداد کل کلمات در واژه‌نامه است.\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "# کامپایل کردن مدل: تعریف تابع هزینه، بهینه‌ساز و معیار ارزیابی\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# --- ۳. آموزش مدل ---\n",
        "# تعداد epochs را به 200 افزایش می‌دهیم.\n",
        "# این مرحله ممکن است زمان‌بر باشد، به خصوص اگر از GPU استفاده نکنید.\n",
        "print(\"\\nشروع آموزش مدل GRU...\")\n",
        "history = model.fit(X, y, epochs=200, verbose=1) # verbose=1 برای نمایش جزئیات آموزش\n",
        "\n",
        "print(\"\\nآموزش مدل به پایان رسید.\")\n",
        "print(f\"دقت نهایی مدل در آموزش: {history.history['accuracy'][-1]:.4f}\")\n",
        "print(f\"خطای نهایی مدل در آموزش: {history.history['loss'][-1]:.4f}\")\n",
        "\n",
        "# --- ۴. تولید متن با مدل آموزش‌دیده ---\n",
        "# تابعی برای تولید کلمات بعدی بر اساس یک متن اولیه (seed text)\n",
        "def generate_text(seed_text, next_words, model, max_sequence_len, tokenizer):\n",
        "    generated_text = seed_text\n",
        "    for _ in range(next_words):\n",
        "        # تبدیل متن اولیه به دنباله عددی\n",
        "        token_list = tokenizer.texts_to_sequences([generated_text])[0]\n",
        "        # هم‌اندازه‌سازی دنباله برای ورودی مدل\n",
        "        token_list = tf.keras.preprocessing.sequence.pad_sequences([token_list],\n",
        "                                                                  maxlen=max_sequence_len-1,\n",
        "                                                                  padding='pre')\n",
        "\n",
        "        # پیش‌بینی احتمال هر کلمه به عنوان کلمه بعدی\n",
        "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
        "        # انتخاب کلمه‌ای با بالاترین احتمال (argmax)\n",
        "        predicted_word_index = np.argmax(predicted_probs)\n",
        "\n",
        "        output_word = \"\"\n",
        "        # پیدا کردن کلمه متناظر با ایندکس پیش‌بینی شده\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_word_index:\n",
        "                output_word = word\n",
        "                break\n",
        "\n",
        "        # اگر کلمه‌ای پیدا نشد (مثلاً ایندکس 0 که برای padding است)\n",
        "        if output_word == \"\":\n",
        "            output_word = \"<unk>\" # کلمه ناشناخته\n",
        "\n",
        "        generated_text += \" \" + output_word\n",
        "    return generated_text\n",
        "\n",
        "# --- امتحان تولید متن ---\n",
        "# یک کلمه یا عبارت اولیه بدهید تا مدل از آنجا شروع به تولید متن کند.\n",
        "# سعی کنید از کلماتی استفاده کنید که در متن آموزشی وجود دارند.\n",
        "seed_text_input_1 = \"جهان هستی\"\n",
        "num_words_to_generate = 20 # تعداد کلماتی که می‌خواهید مدل تولید کند\n",
        "\n",
        "print(f\"\\nشروع تولید متن با عبارت اولیه: '{seed_text_input_1}'\")\n",
        "generated_sentence_1 = generate_text(seed_text_input_1, num_words_to_generate, model, max_sequence_len, tokenizer)\n",
        "print(f\"\\nمتن تولید شده توسط مدل:\\n{generated_sentence_1}\")\n",
        "\n",
        "# مثال دیگر\n",
        "seed_text_input_2 = \"علم به ما\"\n",
        "generated_sentence_2 = generate_text(seed_text_input_2, num_words_to_generate, model, max_sequence_len, tokenizer)\n",
        "print(f\"\\nمتن تولید شده دیگر توسط مدل:\\n{generated_sentence_2}\")\n",
        "\n",
        "# مثال سوم\n",
        "seed_text_input_3 = \"فناوری نیز\"\n",
        "generated_sentence_3 = generate_text(seed_text_input_3, num_words_to_generate, model, max_sequence_len, tokenizer)\n",
        "print(f\"\\nمتن تولید شده سوم توسط مدل:\\n{generated_sentence_3}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "کتابخانه‌ها با موفقیت وارد شدند.\n",
            "\n",
            "متن اصلی برای آموزش (بخش اول):\n",
            "\n",
            "جهان هستی پر از شگفتی‌هاست. هر ستاره در آسمان شب، داستانی ناگفته دارد. کهکشان‌ها با میلیاردها ستاره، منظومه‌های شمسی بی‌شمار را در خود جای داده‌اند. زمین، سیاره آبی ما، تنها گوشه‌ای از این عظمت بی‌کران است. حیات در آن به شکل‌های گوناگون جریان دارد. از کوچکترین میکروارگانیسم‌ها تا بزرگترین نهنگ‌ها. همه و همه بخشی از این چرخه شگفت‌انگیز هستند.\n",
            "\n",
            "علم به ما کمک می‌کند تا این رازها را کشف کنیم. فیزیک، شیمی، زیست‌شناسی، و نجوم. هر کدام دریچه‌ای نو به سوی درک عمیق‌تر جهان می‌گشایند. اکتشافات علمی، مرزه...\n",
            "\n",
            "تعداد کلمات منحصر به فرد در واژه‌نامه: 293\n",
            "\n",
            "تعداد کل کلمات منحصر به فرد در واژه‌نامه (با احتساب صفر): 294\n",
            "\n",
            "تعداد دنباله‌های ورودی برای آموزش: 2310\n",
            "\n",
            "نمونه‌ای از دنباله‌های ورودی (اعداد):\n",
            "[[26, 61], [26, 61, 62], [26, 61, 62, 2], [26, 61, 62, 2, 63], [26, 61, 62, 2, 63, 12]]\n",
            "\n",
            "حداکثر طول دنباله در داده‌های آموزشی: 59\n",
            "\n",
            "ابعاد ورودی (X) برای مدل: (2310, 58)\n",
            "ابعاد خروجی (y) برای مدل (one-hot): (2310, 294)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "شروع آموزش مدل GRU...\n",
            "Epoch 1/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.0486 - loss: 5.4661\n",
            "Epoch 2/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.1834 - loss: 3.8577\n",
            "Epoch 3/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5599 - loss: 1.4745\n",
            "Epoch 4/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8566 - loss: 0.5255\n",
            "Epoch 5/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9851 - loss: 0.1220\n",
            "Epoch 6/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9975 - loss: 0.0491\n",
            "Epoch 7/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9993 - loss: 0.0280\n",
            "Epoch 8/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9993 - loss: 0.0200\n",
            "Epoch 9/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9992 - loss: 0.0136\n",
            "Epoch 10/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9992 - loss: 0.0110\n",
            "Epoch 11/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9996 - loss: 0.0091\n",
            "Epoch 12/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9983 - loss: 0.0117\n",
            "Epoch 13/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0054\n",
            "Epoch 14/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9997 - loss: 0.0063\n",
            "Epoch 15/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9999 - loss: 0.0056\n",
            "Epoch 16/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9998 - loss: 0.0047\n",
            "Epoch 17/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9998 - loss: 0.0040\n",
            "Epoch 18/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9986 - loss: 0.0057\n",
            "Epoch 19/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0026\n",
            "Epoch 20/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9990 - loss: 0.0048\n",
            "Epoch 21/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0022\n",
            "Epoch 22/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9995 - loss: 0.0036\n",
            "Epoch 23/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9999 - loss: 0.0021\n",
            "Epoch 24/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9999 - loss: 0.0039\n",
            "Epoch 25/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0021\n",
            "Epoch 26/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9963 - loss: 0.0057\n",
            "Epoch 27/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9998 - loss: 0.0022\n",
            "Epoch 28/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9991 - loss: 0.0035\n",
            "Epoch 29/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9998 - loss: 0.0020\n",
            "Epoch 30/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9988 - loss: 0.0029\n",
            "Epoch 31/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9992 - loss: 0.0033\n",
            "Epoch 32/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9999 - loss: 0.0012\n",
            "Epoch 33/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9992 - loss: 0.0023\n",
            "Epoch 34/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 8.8005e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9286 - loss: 0.2562\n",
            "Epoch 36/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9332 - loss: 0.2480\n",
            "Epoch 37/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9968 - loss: 0.0190\n",
            "Epoch 38/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9993 - loss: 0.0047\n",
            "Epoch 39/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9996 - loss: 0.0045\n",
            "Epoch 40/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9999 - loss: 0.0016\n",
            "Epoch 41/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9986 - loss: 0.0033\n",
            "Epoch 42/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9994 - loss: 0.0028\n",
            "Epoch 43/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9992 - loss: 0.0031\n",
            "Epoch 44/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9989 - loss: 0.0038\n",
            "Epoch 45/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9995 - loss: 0.0045\n",
            "Epoch 46/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9998 - loss: 0.0018\n",
            "Epoch 47/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9996 - loss: 0.0018\n",
            "Epoch 48/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9998 - loss: 0.0016\n",
            "Epoch 49/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9984 - loss: 0.0030\n",
            "Epoch 50/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9981 - loss: 0.0046\n",
            "Epoch 51/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9999 - loss: 0.0010\n",
            "Epoch 52/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9987 - loss: 0.0029\n",
            "Epoch 53/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9999 - loss: 0.0010\n",
            "Epoch 54/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9994 - loss: 0.0024\n",
            "Epoch 55/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9997 - loss: 0.0018\n",
            "Epoch 56/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9999 - loss: 0.0016\n",
            "Epoch 57/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9980 - loss: 0.0032\n",
            "Epoch 58/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9991 - loss: 0.0028\n",
            "Epoch 59/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9986 - loss: 0.0058\n",
            "Epoch 60/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9998 - loss: 0.0013\n",
            "Epoch 61/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9993 - loss: 0.0023\n",
            "Epoch 62/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9997 - loss: 0.0029\n",
            "Epoch 63/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9998 - loss: 0.0011\n",
            "Epoch 64/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9994 - loss: 0.0039\n",
            "Epoch 65/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9995 - loss: 0.0025\n",
            "Epoch 66/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9996 - loss: 0.0017\n",
            "Epoch 67/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9993 - loss: 0.0024\n",
            "Epoch 68/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9999 - loss: 5.6885e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9978 - loss: 0.0030\n",
            "Epoch 70/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9998 - loss: 0.0012\n",
            "Epoch 71/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9994 - loss: 0.0021\n",
            "Epoch 72/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 3.4707e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9984 - loss: 0.0020\n",
            "Epoch 74/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9995 - loss: 0.0019\n",
            "Epoch 75/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 4.1187e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9997 - loss: 0.0018\n",
            "Epoch 77/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9999 - loss: 7.3533e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9993 - loss: 0.0023\n",
            "Epoch 79/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9992 - loss: 0.0034\n",
            "Epoch 80/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9999 - loss: 6.8988e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9995 - loss: 0.0014\n",
            "Epoch 82/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 3.3099e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9993 - loss: 0.0012\n",
            "Epoch 84/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9993 - loss: 0.0015\n",
            "Epoch 85/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9997 - loss: 0.0010\n",
            "Epoch 86/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9998 - loss: 0.0011\n",
            "Epoch 87/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9988 - loss: 0.0028\n",
            "Epoch 88/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9983 - loss: 0.0034\n",
            "Epoch 89/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9999 - loss: 7.3062e-04\n",
            "Epoch 90/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 7.3772e-04\n",
            "Epoch 91/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9995 - loss: 0.0016\n",
            "Epoch 92/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9985 - loss: 0.0042\n",
            "Epoch 93/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9998 - loss: 8.8301e-04\n",
            "Epoch 94/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9997 - loss: 0.0026\n",
            "Epoch 95/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9999 - loss: 6.6482e-04\n",
            "Epoch 96/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9994 - loss: 0.0013\n",
            "Epoch 97/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "Epoch 98/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9998 - loss: 0.0016\n",
            "Epoch 99/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "Epoch 100/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9990 - loss: 0.0033\n",
            "Epoch 101/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9998 - loss: 0.0013\n",
            "Epoch 102/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9995 - loss: 0.0011\n",
            "Epoch 103/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9982 - loss: 0.0038\n",
            "Epoch 104/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9999 - loss: 3.6563e-04\n",
            "Epoch 105/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9986 - loss: 0.0032\n",
            "Epoch 106/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9994 - loss: 0.0020\n",
            "Epoch 107/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9998 - loss: 0.0011\n",
            "Epoch 108/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9980 - loss: 0.0041\n",
            "Epoch 109/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9999 - loss: 0.0011\n",
            "Epoch 110/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9999 - loss: 9.8051e-04\n",
            "Epoch 111/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9992 - loss: 0.0016\n",
            "Epoch 112/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9995 - loss: 0.0020\n",
            "Epoch 113/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9997 - loss: 0.0014\n",
            "Epoch 114/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9987 - loss: 0.0013\n",
            "Epoch 115/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9982 - loss: 0.0033\n",
            "Epoch 116/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9998 - loss: 0.0011\n",
            "Epoch 117/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9992 - loss: 0.0011\n",
            "Epoch 118/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9996 - loss: 9.6108e-04\n",
            "Epoch 119/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9993 - loss: 0.0020\n",
            "Epoch 120/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9997 - loss: 0.0011\n",
            "Epoch 121/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9999 - loss: 8.6520e-04\n",
            "Epoch 122/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9993 - loss: 0.0015\n",
            "Epoch 123/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9998 - loss: 0.0010\n",
            "Epoch 124/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9997 - loss: 0.0026\n",
            "Epoch 125/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9984 - loss: 0.0036\n",
            "Epoch 126/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9994 - loss: 0.0025\n",
            "Epoch 127/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9998 - loss: 0.0011\n",
            "Epoch 128/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9984 - loss: 0.0035\n",
            "Epoch 129/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9993 - loss: 0.0028\n",
            "Epoch 130/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9999 - loss: 5.5124e-04\n",
            "Epoch 131/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9991 - loss: 0.0028\n",
            "Epoch 132/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9994 - loss: 0.0025\n",
            "Epoch 133/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9999 - loss: 6.5856e-04\n",
            "Epoch 134/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9981 - loss: 0.0036\n",
            "Epoch 135/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9999 - loss: 6.9815e-04\n",
            "Epoch 136/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9990 - loss: 0.0019\n",
            "Epoch 137/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9998 - loss: 7.8401e-04\n",
            "Epoch 138/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9991 - loss: 0.0020\n",
            "Epoch 139/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9995 - loss: 0.0026\n",
            "Epoch 140/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9998 - loss: 5.7495e-04\n",
            "Epoch 141/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9979 - loss: 0.0085\n",
            "Epoch 142/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8162 - loss: 0.7371\n",
            "Epoch 143/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9917 - loss: 0.0479\n",
            "Epoch 144/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9997 - loss: 0.0026\n",
            "Epoch 145/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9997 - loss: 0.0019\n",
            "Epoch 146/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9993 - loss: 0.0033\n",
            "Epoch 147/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9999 - loss: 8.5576e-04\n",
            "Epoch 148/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9998 - loss: 0.0026\n",
            "Epoch 149/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9980 - loss: 0.0046\n",
            "Epoch 150/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9997 - loss: 0.0016\n",
            "Epoch 151/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9999 - loss: 6.7326e-04\n",
            "Epoch 152/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9955 - loss: 0.0051\n",
            "Epoch 153/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9999 - loss: 6.5611e-04\n",
            "Epoch 154/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9996 - loss: 0.0012\n",
            "Epoch 155/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9989 - loss: 0.0083\n",
            "Epoch 156/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9991 - loss: 0.0040\n",
            "Epoch 157/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9998 - loss: 0.0011\n",
            "Epoch 158/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 4.6122e-04\n",
            "Epoch 159/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9988 - loss: 0.0023\n",
            "Epoch 160/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9991 - loss: 0.0014\n",
            "Epoch 161/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 4.3232e-04\n",
            "Epoch 162/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9993 - loss: 0.0018\n",
            "Epoch 163/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9999 - loss: 6.3628e-04\n",
            "Epoch 164/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9989 - loss: 0.0021\n",
            "Epoch 165/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9994 - loss: 0.0025\n",
            "Epoch 166/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9994 - loss: 0.0036\n",
            "Epoch 167/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9978 - loss: 0.0078\n",
            "Epoch 168/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9996 - loss: 0.0028\n",
            "Epoch 169/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9989 - loss: 0.0036\n",
            "Epoch 170/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9992 - loss: 0.0031\n",
            "Epoch 171/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9984 - loss: 0.0056\n",
            "Epoch 172/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9999 - loss: 3.5211e-04\n",
            "Epoch 173/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 4.8358e-04\n",
            "Epoch 174/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9993 - loss: 0.0014\n",
            "Epoch 175/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9992 - loss: 0.0012\n",
            "Epoch 176/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9998 - loss: 9.5304e-04\n",
            "Epoch 177/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9996 - loss: 0.0018\n",
            "Epoch 178/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9992 - loss: 0.0026\n",
            "Epoch 179/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9989 - loss: 0.0095\n",
            "Epoch 180/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9995 - loss: 0.0027\n",
            "Epoch 181/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9995 - loss: 0.0017\n",
            "Epoch 182/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9996 - loss: 0.0030\n",
            "Epoch 183/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9988 - loss: 0.0042\n",
            "Epoch 184/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9998 - loss: 0.0012\n",
            "Epoch 185/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9992 - loss: 0.0036\n",
            "Epoch 186/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9997 - loss: 0.0016\n",
            "Epoch 187/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 3.1959e-04\n",
            "Epoch 188/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9999 - loss: 0.0013\n",
            "Epoch 189/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9978 - loss: 0.0030\n",
            "Epoch 190/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9991 - loss: 0.0027\n",
            "Epoch 191/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9994 - loss: 0.0014\n",
            "Epoch 192/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9993 - loss: 0.0028\n",
            "Epoch 193/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9995 - loss: 0.0030\n",
            "Epoch 194/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9995 - loss: 0.0014\n",
            "Epoch 195/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9993 - loss: 0.0027\n",
            "Epoch 196/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9995 - loss: 0.0021\n",
            "Epoch 197/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9994 - loss: 0.0042\n",
            "Epoch 198/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9997 - loss: 0.0011\n",
            "Epoch 199/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9999 - loss: 4.8848e-04\n",
            "Epoch 200/200\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9989 - loss: 0.0028\n",
            "\n",
            "آموزش مدل به پایان رسید.\n",
            "دقت نهایی مدل در آموزش: 0.9991\n",
            "خطای نهایی مدل در آموزش: 0.0020\n",
            "\n",
            "شروع تولید متن با عبارت اولیه: 'جهان هستی'\n",
            "\n",
            "متن تولید شده توسط مدل:\n",
            "جهان هستی پر از شگفتی‌هاست هر ستاره در آسمان شب، داستانی ناگفته دارد کهکشان‌ها با میلیاردها ستاره، منظومه‌های شمسی بی‌شمار را در\n",
            "\n",
            "متن تولید شده دیگر توسط مدل:\n",
            "علم به ما کمک می‌کند تا این رازها را کشف کنیم فیزیک، شیمی، زیست‌شناسی، و نجوم هر کدام دریچه‌ای نو به سوی درک\n",
            "\n",
            "متن تولید شده سوم توسط مدل:\n",
            "فناوری نیز نقش مهمی در این مسیر ایفا می‌کند از تلسکوپ‌های فضایی قدرتمند تا میکروسکوپ‌های الکترونی پیشرفته ابزارهایی که به ما امکان\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eABhYkTv5TqX",
        "outputId": "3c81bf94-6e67-4504-8ee7-bc54afb55d16"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}